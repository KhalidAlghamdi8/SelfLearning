{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\kalgh\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c9c9e71af474ab7b9d87b64e522c049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83d0ceb15e704cecb2287567c3ef169e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2ffd17f4aa441a48a872ad9b8037dc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/3 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da81737f9c2c417d81d3b243d9db08d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86390be219054b99b1d21b58d5676f83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling imdb_reviews-train.tfrecord...:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d11142a879042328d9604adaaf01b2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "050e8ee1600741b38542c41091683495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling imdb_reviews-test.tfrecord...:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7524db2005b140a68bf09fb2ef913846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating unsupervised examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "173cd43b71c44a7990e47fb8b7781a14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling imdb_reviews-unsupervised.tfrecord...:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset imdb_reviews downloaded and prepared to C:\\Users\\kalgh\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    \"imdb_reviews\",\n",
    "    split=[\"train\", \"test\"],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,  # will return tuple (img, label) otherwise dict\n",
    "    with_info=True,  # able to get info about dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfds.core.DatasetInfo(\n",
      "    name='imdb_reviews',\n",
      "    full_name='imdb_reviews/plain_text/1.0.0',\n",
      "    description=\"\"\"\n",
      "    Large Movie Review Dataset.\n",
      "    This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well.\n",
      "    \"\"\",\n",
      "    config_description=\"\"\"\n",
      "    Plain text\n",
      "    \"\"\",\n",
      "    homepage='http://ai.stanford.edu/~amaas/data/sentiment/',\n",
      "    data_path='C:\\\\Users\\\\kalgh\\\\tensorflow_datasets\\\\imdb_reviews\\\\plain_text\\\\1.0.0',\n",
      "    download_size=80.23 MiB,\n",
      "    dataset_size=129.83 MiB,\n",
      "    features=FeaturesDict({\n",
      "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
      "        'text': Text(shape=(), dtype=tf.string),\n",
      "    }),\n",
      "    supervised_keys=('text', 'label'),\n",
      "    splits={\n",
      "        'test': <SplitInfo num_examples=25000, num_shards=1>,\n",
      "        'train': <SplitInfo num_examples=25000, num_shards=1>,\n",
      "        'unsupervised': <SplitInfo num_examples=50000, num_shards=1>,\n",
      "    },\n",
      "    citation=\"\"\"@InProceedings{maas-EtAl:2011:ACL-HLT2011,\n",
      "      author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},\n",
      "      title     = {Learning Word Vectors for Sentiment Analysis},\n",
      "      booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},\n",
      "      month     = {June},\n",
      "      year      = {2011},\n",
      "      address   = {Portland, Oregon, USA},\n",
      "      publisher = {Association for Computational Linguistics},\n",
      "      pages     = {142--150},\n",
      "      url       = {http://www.aclweb.org/anthology/P11-1015}\n",
      "    }\"\"\",\n",
      ")\n",
      "tf.Tensor(b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\", shape=(), dtype=string)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kalgh\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3406: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "print(ds_info)\n",
    "\n",
    "for text, lable in ds_train:\n",
    "    print(text)\n",
    "    import sys\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow_datasets.core.features' has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\kalgh\\Desktop\\pythonProject\\TF\\TensorFlow Datasets IMDB reviews.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/kalgh/Desktop/pythonProject/TF/TensorFlow%20Datasets%20IMDB%20reviews.ipynb#ch0000003?line=0'>1</a>\u001b[0m tokenizer \u001b[39m=\u001b[39m tfds\u001b[39m.\u001b[39;49mfeatures\u001b[39m.\u001b[39;49mtext\u001b[39m.\u001b[39mTokenizer()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kalgh/Desktop/pythonProject/TF/TensorFlow%20Datasets%20IMDB%20reviews.ipynb#ch0000003?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbuild_vocabulary\u001b[39m():\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kalgh/Desktop/pythonProject/TF/TensorFlow%20Datasets%20IMDB%20reviews.ipynb#ch0000003?line=3'>4</a>\u001b[0m     vocabulary \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow_datasets.core.features' has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "tokenizer = tfds.features.text.Tokenizer()\n",
    "\n",
    "def build_vocabulary():\n",
    "    vocabulary = set()\n",
    "    for text, _ in ds_train:\n",
    "        vocabulary.update(tokenizer.tokenize(text.numpy().lower()))\n",
    "    return vocabulary\n",
    "\n",
    "\n",
    "vocabulary = build_vocabulary()\n",
    "\n",
    "encoder = tfds.features.text.TokenTextEncoder(\n",
    "    list(vocabulary), oov_token=\"<UNK>\", lowercase=True, tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "def my_enc(text_tensor, label):\n",
    "    encoded_text = encoder.encode(text_tensor.numpy())\n",
    "    return encoded_text, label\n",
    "\n",
    "\n",
    "def encode_map_fn(text, label):\n",
    "    # py_func doesn't set the shape of the returned tensors.\n",
    "    encoded_text, label = tf.py_function(\n",
    "        my_enc, inp=[text, label], Tout=(tf.int64, tf.int64)\n",
    "    )\n",
    "\n",
    "    # `tf.data.Datasets` work best if all components have a shape set\n",
    "    #  so set the shapes manually:\n",
    "    encoded_text.set_shape([None])\n",
    "    label.set_shape([])\n",
    "\n",
    "    return encoded_text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow_datasets.core.features' has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\kalgh\\Desktop\\pythonProject\\TF\\TensorFlow Datasets IMDB reviews.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/kalgh/Desktop/pythonProject/TF/TensorFlow%20Datasets%20IMDB%20reviews.ipynb#ch0000004?line=0'>1</a>\u001b[0m tokenizer \u001b[39m=\u001b[39m tfds\u001b[39m.\u001b[39;49mfeatures\u001b[39m.\u001b[39;49mtext\u001b[39m.\u001b[39mTokenizer()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kalgh/Desktop/pythonProject/TF/TensorFlow%20Datasets%20IMDB%20reviews.ipynb#ch0000004?line=3'>4</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbuild_vocabulary\u001b[39m():\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kalgh/Desktop/pythonProject/TF/TensorFlow%20Datasets%20IMDB%20reviews.ipynb#ch0000004?line=4'>5</a>\u001b[0m     vocabulary \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow_datasets.core.features' has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "tokenizer = tfds.features.text.Tokenizer()\n",
    "\n",
    "\n",
    "def build_vocabulary():\n",
    "    vocabulary = set()\n",
    "    for text, _ in ds_train:\n",
    "        vocabulary.update(tokenizer.tokenize(text.numpy().lower()))\n",
    "    return vocabulary\n",
    "\n",
    "\n",
    "vocabulary = build_vocabulary()\n",
    "\n",
    "encoder = tfds.features.text.TokenTextEncoder(\n",
    "    list(vocabulary), oov_token=\"<UNK>\", lowercase=True, tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "\n",
    "def my_enc(text_tensor, label):\n",
    "    encoded_text = encoder.encode(text_tensor.numpy())\n",
    "    return encoded_text, label\n",
    "\n",
    "\n",
    "def encode_map_fn(text, label):\n",
    "    # py_func doesn't set the shape of the returned tensors.\n",
    "    encoded_text, label = tf.py_function(\n",
    "        my_enc, inp=[text, label], Tout=(tf.int64, tf.int64)\n",
    "    )\n",
    "\n",
    "    # `tf.data.Datasets` work best if all components have a shape set\n",
    "    #  so set the shapes manually:\n",
    "    encoded_text.set_shape([None])\n",
    "    label.set_shape([])\n",
    "\n",
    "    return encoded_text, label\n",
    "\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "ds_train = ds_train.map(encode_map_fn, num_parallel_calls=AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(1000)\n",
    "ds_train = ds_train.padded_batch(32, padded_shapes=([None], ()))\n",
    "ds_train = ds_train.prefetch(AUTOTUNE)\n",
    "\n",
    "ds_test = ds_test.map(encode_map_fn)\n",
    "ds_test = ds_test.padded_batch(32, padded_shapes=([None], ()))\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Masking(mask_value=0),\n",
    "        layers.Embedding(input_dim=len(vocabulary) + 2, output_dim=32),\n",
    "        layers.GlobalAveragePooling1D(),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(3e-4, clipnorm=1),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model.fit(ds_train, epochs=15, verbose=2)\n",
    "model.evaluate(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "93a850cdd8e1ced0015abffd1c74857b7727d52a3b5bd3cee8894c4cf53924e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
